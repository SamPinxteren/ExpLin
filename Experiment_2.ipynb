{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "535aaca0-69ec-4783-8649-c8e209298242",
   "metadata": {},
   "source": [
    "In this second experiment, we compare RangeGrad2 to a number of existing methods. Here, we use the VGG19 network trained on the ImageNet dataset. We compare our results to the simple gradient (baseline), SmoothGrad and GradCam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57383f5-7430-4be1-909d-af0bb140710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from random import choices\n",
    "from minmax.lmm_models import vgg, resnet, densenet\n",
    "from torchvision.models import vgg as vggn\n",
    "from time import time\n",
    "from minmax.ImageNetClasses import classes\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_transforms = {\n",
    "    'train': T.Compose([\n",
    "        T.Resize((224,224)),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'inverse': T.Compose([\n",
    "        T.Normalize(mean=[0, 0, 0], std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "        T.Normalize(mean=[-0.485, -0.456, -0.406], std=[1, 1, 1]),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "testset = torchvision.datasets.ImageNet(\n",
    "    root='~/datasets/ImageNet',\n",
    "    split=\"val\",\n",
    "    transform=data_transforms['val']\n",
    ")\n",
    "\n",
    "#samples = [8922,13899,16096,4753,9301,37782,35062,25899,23031,44597] + choices(range(len(testset)), k=10) \n",
    "#samples = [18835, 14470, 33868, 25621, 33312, 40082, 46358]# + choices(range(len(testset)), k=50)\n",
    "samples = choices(range(len(testset)), k=10)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=1,\n",
    "    num_workers=2,\n",
    "    sampler=samples\n",
    "    #shuffle=True\n",
    ")\n",
    "\n",
    "netn = vggn.vgg19(pretrained=True)\n",
    "netn.eval()\n",
    "\n",
    "net = vgg.vgg19(pretrained=True)\n",
    "net.eval()\n",
    "\n",
    "print(\"Loading Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b01fbb2-bcd8-48bf-a2b8-89ddef0e0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from minmax.mm_linearize import mmTensor, explainV1, explainV2, explainGradient\n",
    "import scipy.ndimage as ndimage\n",
    "import os\n",
    "from minmax.ImageNetClasses import classes\n",
    "from pytorch_grad_cam import GradCAM\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from captum.attr import (\n",
    "    Occlusion,\n",
    "    NoiseTunnel,\n",
    "    DeepLiftShap,\n",
    "    Saliency,\n",
    "    GuidedGradCam\n",
    ")\n",
    "\n",
    "OUTPUT_FOLDER = \"Experiment_2\"\n",
    "try:\n",
    "    os.mkdir(OUTPUT_FOLDER)\n",
    "    print(\"Output Folder Created\")\n",
    "except FileExistsError:\n",
    "    print(\"Output Folder Exists\")\n",
    "\n",
    "for i, (data, target) in enumerate(testloader):\n",
    "    # Plot all versions of the explanation\n",
    "    fig, axs = plt.subplots(1,7)\n",
    "    fig.set_size_inches(17,10)\n",
    "    \n",
    "    info = {\n",
    "        'out': OUTPUT_FOLDER,\n",
    "        'snum': samples[i],\n",
    "        'class': classes[target.item()]\n",
    "    }\n",
    "    \n",
    "    # Guided GradCam\n",
    "    info['method'] = 'Guided-GradCam'\n",
    "    expl = GuidedGradCam(netn, netn.features[-1])\n",
    "    explGuidedGradCam = expl.attribute(data, target=target)\n",
    "    explGuidedGradCam = explGuidedGradCam.detach().numpy()\n",
    "    explGuidedGradCam = explGuidedGradCam.sum(axis=0)\n",
    "    explGuidedGradCam = np.linalg.norm(explGuidedGradCam, axis=0)\n",
    "    \n",
    "    axs[0].axis(\"off\")\n",
    "    axs[0].imshow(explGuidedGradCam, cmap=plt.cm.Reds)\n",
    "    axs[0].set_title(info['method'])\n",
    "    plt.imsave(\"{out}/{snum}_{method}.png\".format(**info), explGuidedGradCam, cmap=plt.cm.Reds)\n",
    "\n",
    "    # SmoothGrad\n",
    "    info['method'] = 'SmoothGrad'\n",
    "    timeSmoothGrad = datetime.now()\n",
    "    saliency = Saliency(netn)\n",
    "    nt = NoiseTunnel(saliency)\n",
    "    explSmoothGrad = nt.attribute(data, target=target, nt_type='smoothgrad', nt_samples=15)\n",
    "    explSmoothGrad = explSmoothGrad.detach().numpy().sum(axis=0)\n",
    "    explSmoothGrad = np.linalg.norm(explSmoothGrad, axis=0)\n",
    "    \n",
    "    axs[1].axis(\"off\")\n",
    "    axs[1].imshow(explSmoothGrad, cmap=plt.cm.Reds)\n",
    "    axs[1].set_title(info['method'])\n",
    "    plt.imsave(\"{out}/{snum}_{method}.png\".format(**info), explSmoothGrad, cmap=plt.cm.Reds)\n",
    "    \n",
    "    # DeepLiftShap\n",
    "    info['method'] = 'DeepLiftShap'\n",
    "    timeShapley = datetime.now()\n",
    "    dist = torch.cat([data * 0, data * 1])\n",
    "    expl = DeepLiftShap(netn)\n",
    "    explShapley = expl.attribute(data, target=target, baselines=dist)\n",
    "    explShapley = explShapley.detach().numpy().sum(axis=0)\n",
    "    explShapley = np.linalg.norm(explShapley, axis=0)\n",
    "    \n",
    "    axs[2].axis(\"off\")\n",
    "    axs[2].imshow(explShapley, cmap=plt.cm.Reds)\n",
    "    axs[2].set_title(info['method'])\n",
    "    plt.imsave(\"{out}/{snum}_{method}.png\".format(**info), explShapley, cmap=plt.cm.Reds)\n",
    "\n",
    "    # Occlusion\n",
    "    info['method'] = 'Occlusion'\n",
    "    expl = Occlusion(netn)\n",
    "    explOcclusion = expl.attribute(data, target=target, strides=(3,25,25), sliding_window_shapes=(3,50,50))\n",
    "    explOcclusion = explOcclusion.detach().numpy().sum(axis=0).sum(axis=0)\n",
    "    if not target: explOcclusion = -explOcclusion\n",
    "    explOcclusion -= explOcclusion.min()\n",
    "    explOcclusion /= explOcclusion.max()\n",
    "    \n",
    "    axs[3].axis(\"off\")\n",
    "    axs[3].imshow(explOcclusion, cmap=plt.cm.Reds)\n",
    "    axs[3].set_title(info['method'])\n",
    "    plt.imsave(\"{out}/{snum}_{method}.png\".format(**info), explOcclusion, cmap=plt.cm.Reds)\n",
    "\n",
    "    # Gradient\n",
    "    info['method'] = 'Gradient'\n",
    "    explGradient, _ = explainGradient(net, data)\n",
    "    \n",
    "    axs[4].axis(\"off\")\n",
    "    axs[4].imshow(explGradient, cmap=plt.cm.Reds)\n",
    "    axs[4].set_title(info['method'])\n",
    "    plt.imsave(\"{out}/{snum}_{method}.png\".format(**info), explGradient, cmap=plt.cm.Reds)\n",
    "\n",
    "    # RangeGrad\n",
    "    info['method'] = 'RangeGrad'\n",
    "    explRangeGrad, _ = explainV2(net, data, scale=1/100, width=1/1000)\n",
    "    axs[5].axis(\"off\")\n",
    "    axs[5].imshow(explRangeGrad, cmap=plt.cm.Reds)\n",
    "    axs[5].set_title(info['method'])\n",
    "    plt.imsave(\"{out}/{snum}_{method}.png\".format(**info), explRangeGrad, cmap=plt.cm.Reds)\n",
    "\n",
    "    # Image\n",
    "    image = data_transforms['inverse'](data)[0].movedim(0,2).numpy()\n",
    "    axs[6].axis(\"off\")\n",
    "    axs[6].imshow(image)\n",
    "    axs[6].set_title(\"Original {} - {}\".format(samples[i], classes[target.item()]))\n",
    "    plt.imsave(\"{out}/{snum}_original.png\".format(**info), image)\n",
    "    plt.savefig(\"{out}/{snum}.png\".format(**info))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fcbd9f-7faf-43d8-a711-e2e2a7bacb19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9227e-689c-4591-bb89-9c7481fb9133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV3.8",
   "language": "python",
   "name": "env3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
